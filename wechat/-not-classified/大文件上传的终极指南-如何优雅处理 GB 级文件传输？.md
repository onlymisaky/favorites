> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s/8VAHmDDavIR8oEfjCT0YLw)

```
点击上方 程序员成长指北，关注公众号回复1，加入高级Node交流群你是否曾尝试上传一个大视频或压缩包，却遭遇浏览器卡死或网络中断？本文将带你彻底掌握分片上传与断点续传的核心原理，让GB级文件传输不再是难题。为什么我们需要专门的大文件上传方案？在日常开发中，我们常常遇到这样的场景：用户需要上传一个5GB的视频文件，但传统上传方式直接导致浏览器卡死，或者上传到一半网络中断，只能无奈重新开始。传统表单上传就像试图一口吞下一个汉堡——不仅困难，而且容易噎住。相比之下，大文件上传更像是用刀叉优雅地享用美食——将大文件切成小块，逐块处理。核心技术原理：分而治之大文件上传的核心思想很简单： "分而治之" 。就像搬家时不会把整个房子一次性搬走，而是分成多个箱子分批运输一样，大文件上传也是将文件切成多个小片段，分别上传，最后在服务器端重新组装。前端实现详解1. 文件分片处理：化整为零首先，我们需要将大文件切割成多个小片段。HTML5的File API提供了完美的解决方案：// 切片函数：将大文件切成固定大小的片段function createChunk(file, size = 5 * 1024 * 1024) {    const chunkList = []    let cur = 0    while (cur < file.size) {        // 使用slice方法切割文件        chunkList.push({            file: file.slice(cur, cur + size)        })        cur += size    }    return chunkList}这里的slice()方法类似于数组的slice，但专门用于文件的分割。每个分片默认5MB大小，这个值可以根据网络状况动态调整。2. 分片标识与管理：给每个碎片贴上标签切割后的每个分片都需要有唯一的标识，这样服务器才能正确重组文件：const chunks = chunkList.map(({ file }, index) => {    return {        file,        size: file.size,        chunkName: `${fileObj.name}-${index}`,  // 唯一标识        fileName: fileObj.name,  // 原文件名        index  // 分片序号    }})3. 并发上传控制：多车道同时通行使用Promise.all来并发上传所有分片，但要控制并发数量，避免对服务器造成过大压力：// 控制并发数量，避免服务器过载const MAX_CONCURRENT = 3const requestList = formChunks.map(({ formData, index }) => {    return() => axios.post('http://localhost:3000/upload', formData)})// 使用并发控制函数上传asyncfunction concurrentUpload(tasks, maxConcurrent) {    // 实现并发控制逻辑}concurrentUpload(requestList, MAX_CONCURRENT).then(() => {    // 所有分片上传完成后发送合并请求    axios.post('http://localhost:3000/merge', {        fileName: fileObj.name,        size: 5 * 1024 * 1024    })})后端实现详解1. 分片接收与存储：精心保管每个碎片后端使用multiparty库来处理FormData格式的分片数据：if (req.url === '/upload' && req.method === 'POST') {    const form = new multiparty.Form()    form.parse(req, (err, fields, files) => {        const [file] = files.file;        const [fileName] = fields.fileName;        const [chunkName] = fields.chunkName;                // 创建分片存储目录        const chunkDir = path.resolve(__dirname, 'chunks', `${fileName}-chunks`)        if (!fs.existsSync(chunkDir)) {            fs.mkdirsSync(chunkDir)        }                // 保存分片文件        fs.moveSync(file.path, path.resolve(chunkDir, chunkName))    })}2. 文件合并：拼图大师的工作所有分片上传完成后，后端需要按顺序将它们合并成完整文件：const mergeChunks = async (filePath, fileName, size) => {    // 读取分片目录中的所有文件    let chunksPath = fs.readdirSync(filePath)        // 按分片序号排序    chunksPath.sort((a, b) => {        return a.split('-').pop() - b.split('-').pop()    })    // 按顺序合并所有分片    const arr = chunksPath.map((chunkPath, index) => {        return pipeStream(            path.resolve(filePath, chunkPath),            fs.createWriteStream(path.resolve(filePath, fileName), {                start: index * size,  // 计算写入位置                end: (index + 1) * size            })        )    })    awaitPromise.all(arr)}断点续传：永不中断的上传体验断点续传是大文件上传的关键特性，它确保即使网络中断，也能从中断处继续上传，而不是重新开始。这就像看书时使用书签——即使中途放下，回来时也能从上次停止的地方继续。实现原理前端状态保存：在localStorage中记录已上传的分片信息续传查询：重新上传时，先向后端查询已上传的分片列表跳过已传分片：只上传未完成的分片状态同步：上传完成后更新本地和服务器状态代码实现思路// 续传检查函数async function checkResume(fileName) {    const response = await axios.get(        `http://localhost:3000/uploaded-chunks?fileName=${fileName}`    )    return response.data.uploadedChunks // 返回已上传的分片索引列表}// 上传时跳过已上传的分片const uploadedChunks = await checkResume(fileName)const chunksToUpload = chunks.filter(chunk =>     !uploadedChunks.includes(chunk.index))错误处理与优化：打造健壮的上传系统1. 网络异常重试：永不放弃的勇气对上传失败的分片进行自动重试，可以设置最大重试次数：async function uploadWithRetry(formData, maxRetries = 3) {    let retries = 0    while (retries < maxRetries) {        try {            returnawait axios.post('/upload', formData)        } catch (error) {            retries++            if (retries === maxRetries) throw error            // 指数退避策略：等待时间随重试次数增加            awaitnewPromise(resolve => setTimeout(resolve, 1000 * retries))        }    }}2. 分片完整性校验：确保每一块都完美无缺使用MD5校验确保分片在传输过程中没有损坏：// 前端计算分片MD5const md5 = await calculateMD5(chunk.file)// 后端验证MD5if (md5 !== receivedMD5) {    throw new Error('分片校验失败，可能传输过程中损坏')}3. 进度跟踪：让用户知道进行到哪一步实时显示上传进度，极大提升用户体验：const totalSize = fileObj.sizelet uploadedSize = 0// 监听每个分片的上传进度const onUploadProgress = (progressEvent) => {    uploadedSize += progressEvent.loaded    const percent = (uploadedSize / totalSize) * 100    updateProgressBar(percent) // 更新进度条显示}实际应用场景1. 视频网站优酷、YouTube等视频网站都使用类似的技术来处理用户上传的大视频文件。想象一下，如果没有分片上传，这些平台将无法处理用户上传的高清视频。2. 云存储服务百度网盘、Dropbox等云存储服务支持大文件断点续传。即使网络不稳定，也能保证文件最终上传成功。3. 企业文件传输企业内部系统经常需要传输大型设计文件、数据库备份等。分片上传确保了这些关键业务数据的可靠传输。性能优化建议动态分片大小：根据网络状况动态调整分片大小，网络好时用大分片（如10MB），网络差时用小分片（如1MB）并发控制：限制同时上传的分片数量，避免服务器过载，通常3-5个并发请求为宜压缩传输：对分片进行压缩后再传输，减少网络流量消耗CDN加速：使用CDN节点分散上传压力，提升上传速度常见问题解答Q: 分片大小设置为多少最合适？ A: 通常2-5MB比较合适。太小会增加请求次数，降低整体效率；太大会增加单次失败的风险，重传成本高。Q: 如何保证分片上传的顺序？ A: 分片可以乱序上传，后端根据分片索引进行排序和合并。就像拼图游戏，只要每块有编号，顺序不是问题。Q: 如果合并过程中出错怎么办？ A: 应该实现事务性合并，要么全部成功，要么全部回滚，避免产生损坏的文件。可以在合并前备份，失败时恢复。Q: 如何清理过期或失败的上传任务？ A: 可以设置定时任务，清理超过一定时间（如24小时）未完成的上传任务，释放存储空间。总结大文件上传是一个复杂但非常重要的技术，它涉及到前后端的紧密配合。通过分片上传、断点续传、错误重试等机制，我们可以为用户提供稳定可靠的大文件上传体验。记住，好的技术方案不仅要解决技术问题，更要提升用户体验。在实际开发中，要根据具体业务需求选择合适的方案，并不断优化和改进。本文作者：BUG收容所所长原文地址：https://juejin.cn/post/7546157677799243810希望本文能帮助你深入理解大文件上传的技术原理和实现方法。如果你有任何问题或建议，欢迎在评论区留言讨论！
```

Node 社群

```
我组建了一个氛围特别好的 Node.js 社群，里面有很多 Node.js小伙伴，如果你对Node.js学习感兴趣的话（后续有计划也可以），我们可以一起进行Node.js相关的交流、学习、共建。下方加 考拉 好友回复「Node」即可。

   “分享、点赞、在看” 支持一波

```