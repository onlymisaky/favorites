> æœ¬æ–‡ç”± [ç®€æ‚¦ SimpRead](http://ksria.com/simpread/) è½¬ç ï¼Œ åŸæ–‡åœ°å€ [mp.weixin.qq.com](https://mp.weixin.qq.com/s/gExvNw2nUf5jPXI-KiEBcg)

> æœ¬æ–‡ä½œè€…ä¸º 360 å¥‡èˆå›¢å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ

å‰è¨€
--

åœ¨ AI åº”ç”¨å¿«é€Ÿå‘å±•çš„ä»Šå¤©ï¼Œå‘é‡æ•°æ®åº“å·²æˆä¸ºæ„å»ºæ™ºèƒ½æ£€ç´¢ç³»ç»Ÿçš„æ ¸å¿ƒåŸºç¡€è®¾æ–½ã€‚Milvus ä½œä¸ºä¸€æ¬¾å¼€æºçš„é«˜æ€§èƒ½å‘é‡æ•°æ®åº“ï¼Œåœ¨ RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»ç»Ÿä¸­å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚

æœ¬æ–‡å°†å¸¦ä½ ä»é›¶å¼€å§‹ï¼ŒåŸºäº Milvus æ„å»ºä¸€ä¸ªå®Œæ•´çš„ RAG ç³»ç»Ÿï¼Œæ¶µç›–æ•°æ®å‡†å¤‡ã€å‘é‡æ£€ç´¢ã€ç»“æœé‡æ’ã€ä½ç½®ä¼˜åŒ–ç­‰æ ¸å¿ƒç¯èŠ‚ï¼Œå¹¶åˆ†äº«ç”Ÿäº§ç¯å¢ƒä¸­çš„æœ€ä½³å®è·µå’Œæ€§èƒ½ä¼˜åŒ–æŠ€å·§ã€‚

* * *

1. Milvus ç®€ä»‹ä¸æ ¸å¿ƒç‰¹æ€§
-----------------

### 1.1 ä»€ä¹ˆæ˜¯ Milvusï¼Ÿ

Milvus æ˜¯ä¸€ä¸ªå¼€æºçš„å‘é‡æ•°æ®åº“ï¼Œä¸“ä¸º AI åº”ç”¨è®¾è®¡ï¼Œæ”¯æŒå¤§è§„æ¨¡å‘é‡æ•°æ®çš„å­˜å‚¨ã€ç´¢å¼•å’Œæ£€ç´¢ã€‚å®ƒå…·å¤‡ä»¥ä¸‹æ ¸å¿ƒç‰¹æ€§ï¼š

*   **é«˜æ€§èƒ½**ï¼šæ¯«ç§’çº§å‘é‡æ£€ç´¢ï¼Œæ”¯æŒç™¾ä¸‡åˆ°ç™¾äº¿çº§å‘é‡
    
*   **æ˜“ç”¨æ€§**ï¼šæä¾› Python SDKï¼ŒAPI ç®€æ´ç›´è§‚
    
*   **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²ï¼Œæ°´å¹³æ‰©å±•
    
*   **å¤šç´¢å¼•æ”¯æŒ**ï¼šHNSWã€IVFã€DiskANN ç­‰å¤šç§ç´¢å¼•ç®—æ³•
    
*   **å¤šæ¨¡æ€å‹å¥½**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šç§æ•°æ®ç±»å‹
    

### 1.2 ä¸ºä»€ä¹ˆé€‰æ‹© Milvusï¼Ÿ

åœ¨æ„å»º RAG ç³»ç»Ÿæ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªèƒ½å¤Ÿï¼š

1.  **å¿«é€Ÿæ£€ç´¢**ï¼šä»å¤§è§„æ¨¡æ–‡æ¡£åº“ä¸­å¿«é€Ÿæ‰¾åˆ°ç›¸å…³æ–‡æ¡£
    
2.  **ç²¾ç¡®åŒ¹é…**ï¼šé€šè¿‡å‘é‡ç›¸ä¼¼åº¦æ‰¾åˆ°è¯­ä¹‰ç›¸å…³çš„æ–‡æ¡£
    
3.  **æ˜“äºé›†æˆ**ï¼šä¸ç°æœ‰ AI å·¥å…·é“¾æ— ç¼é›†æˆ
    
4.  **ç”Ÿäº§å°±ç»ª**ï¼šæ”¯æŒé«˜å¹¶å‘ã€é«˜å¯ç”¨éƒ¨ç½²
    

Milvus å®Œç¾æ»¡è¶³è¿™äº›éœ€æ±‚ï¼Œå·²æˆä¸º RAG ç³»ç»Ÿçš„é¦–é€‰å‘é‡æ•°æ®åº“ã€‚

### 1.3 Milvus Lite vs Milvus Server

Milvus æä¾›äº†ä¸¤ç§ä½¿ç”¨æ–¹å¼ï¼š

<table><thead><tr><th><section>ç‰¹æ€§</section></th><th><section>Milvus Lite</section></th><th><section>Milvus Server</section></th></tr></thead><tbody><tr><td><strong>éƒ¨ç½²æ–¹å¼</strong></td><td><section>æœ¬åœ°æ–‡ä»¶ï¼Œæ— éœ€å¯åŠ¨æœåŠ¡</section></td><td><section>ç‹¬ç«‹æœåŠ¡ï¼Œéœ€è¦å¯åŠ¨</section></td></tr><tr><td><strong>é€‚ç”¨åœºæ™¯</strong></td><td><section>å¼€å‘ã€æµ‹è¯•ã€å°è§„æ¨¡åº”ç”¨</section></td><td><section>ç”Ÿäº§ç¯å¢ƒã€å¤§è§„æ¨¡åº”ç”¨</section></td></tr><tr><td><strong>æ•°æ®å­˜å‚¨</strong></td><td><section>æœ¬åœ°æ–‡ä»¶ï¼ˆ.dbï¼‰</section></td><td><section>åˆ†å¸ƒå¼å­˜å‚¨</section></td></tr><tr><td><strong>æ€§èƒ½</strong></td><td><section>é€‚åˆä¸­å°è§„æ¨¡ï¼ˆ&lt;100 ä¸‡å‘é‡ï¼‰</section></td><td><section>æ”¯æŒå¤§è§„æ¨¡ï¼ˆç™¾ä¸‡åˆ°ç™¾äº¿çº§ï¼‰</section></td></tr><tr><td><strong>ä½¿ç”¨æ–¹å¼</strong></td><td><code>MilvusClient(uri="./db")</code></td><td><code>connections.connect(host="localhost")</code></td></tr></tbody></table>

**æœ¬æ–‡ä½¿ç”¨ Milvus Lite**ï¼Œå› ä¸ºå®ƒæ›´ç®€å•ï¼Œé€‚åˆå¿«é€Ÿä¸Šæ‰‹å’Œå¼€å‘æµ‹è¯•ã€‚

* * *

2. ç¯å¢ƒå‡†å¤‡ä¸å®‰è£…
----------

### 2.1 ç³»ç»Ÿè¦æ±‚

*   Python 3.8+
    
*   8GB+ RAMï¼ˆæ¨è 16GBï¼‰
    
*   10GB+ ç£ç›˜ç©ºé—´ï¼ˆç”¨äºå­˜å‚¨å‘é‡å’Œæ¨¡å‹ï¼‰
    

### 2.2 å®‰è£…ä¾èµ–

é¦–å…ˆåˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰ï¼š

```
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒpython3 -m venv venv# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ# macOS/Linux:sourceÂ venv/bin/activate# Windows:# venv\Scripts\activate
```

å®‰è£…å¿…è¦çš„ä¾èµ–ï¼š

```
pip install pymilvus[milvus_lite] Â # åŒ…å«Milvus Litepip install sentence-transformers Â Â # Embeddingæ¨¡å‹pip install transformers Â  Â  Â  Â  Â  Â # é‡æ’æ¨¡å‹pip install torch Â  Â  Â  Â  Â  Â  Â  Â  Â Â # PyTorchï¼ˆé‡æ’æ¨¡å‹éœ€è¦ï¼‰
```

**é‡è¦æç¤º**ï¼šå¿…é¡»å®‰è£…Â `pymilvus[milvus_lite]`ï¼ˆä¸æ˜¯Â `pymilvus`ï¼‰ï¼Œè¿™æ ·æ‰èƒ½ä½¿ç”¨ Milvus Lite çš„æœ¬åœ°æ–‡ä»¶åŠŸèƒ½ã€‚

### 2.3 éªŒè¯å®‰è£…

```
fromÂ pymilvusÂ importÂ MilvusClient# æµ‹è¯•Milvus Liteè¿æ¥client = MilvusClient(uri="./test.db")print("âœ“ Milvus Lite å®‰è£…æˆåŠŸï¼")
```

* * *

3. æ•°æ®å‡†å¤‡ï¼šä»æ–‡æ¡£åˆ°å‘é‡
--------------

### 3.1 æ–‡æ¡£é¢„å¤„ç†

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å°†åŸå§‹æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡ã€‚è¿™ä¸ªè¿‡ç¨‹åŒ…æ‹¬ï¼š

1.  **æ–‡æ¡£åŠ è½½**ï¼šä»æ–‡ä»¶ã€æ•°æ®åº“æˆ– API åŠ è½½æ–‡æ¡£
    
2.  **æ–‡æ¡£åˆ†å—**ï¼šå°†é•¿æ–‡æ¡£åˆ‡åˆ†ä¸ºè¾ƒå°çš„å—ï¼ˆchunksï¼‰
    
3.  **å‘é‡åŒ–**ï¼šä½¿ç”¨ Embedding æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
    

### 3.2 æ–‡æ¡£åˆ†å—ç­–ç•¥

æ–‡æ¡£åˆ†å—æ˜¯ RAG ç³»ç»Ÿçš„å…³é”®æ­¥éª¤ï¼Œç›´æ¥å½±å“æ£€ç´¢æ•ˆæœï¼š

```
defÂ chunk_document(text, chunk_size=512, overlap=50):Â  Â Â """Â  Â  æ–‡æ¡£åˆ†å—Â  Â  Args:Â  Â  Â  Â  text: åŸå§‹æ–‡æ¡£æ–‡æœ¬Â  Â  Â  Â  chunk_size: æ¯å—çš„å¤§å°ï¼ˆå­—ç¬¦æ•°æˆ–tokensï¼‰Â  Â  Â  Â  overlap: å—ä¹‹é—´çš„é‡å å¤§å°ï¼Œä¿è¯ä¸Šä¸‹æ–‡è¿è´¯æ€§Â  Â  Returns:Â  Â  Â  Â  æ–‡æ¡£å—åˆ—è¡¨Â  Â  """Â  Â  chunks = []Â  Â  start =Â 0Â  Â Â whileÂ start < len(text):Â  Â  Â  Â  end = start + chunk_sizeÂ  Â  Â  Â  chunk = text[start:end]Â  Â  Â  Â  chunks.append(chunk)Â  Â  Â  Â  start = end - overlap Â # é‡å ï¼Œä¿è¯ä¸Šä¸‹æ–‡è¿è´¯Â  Â Â returnÂ chunks
```

**åˆ†å—ç­–ç•¥é€‰æ‹©**ï¼š

*   **å›ºå®šå¤§å°åˆ†å—**ï¼šç®€å•å¿«é€Ÿï¼Œé€‚åˆç»“æ„åŒ–æ–‡æ¡£
    
*   **è¯­ä¹‰åˆ†å—**ï¼šæŒ‰å¥å­æˆ–æ®µè½è¾¹ç•Œåˆ†å—ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§
    
*   **æ»‘åŠ¨çª—å£**ï¼šä½¿ç”¨é‡å çª—å£ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤±
    

### 3.3 å‘é‡åŒ–ï¼šé€‰æ‹© Embedding æ¨¡å‹

é€‰æ‹©åˆé€‚çš„ Embedding æ¨¡å‹è‡³å…³é‡è¦ï¼š

<table><thead><tr><th><section>æ¨¡å‹</section></th><th><section>ç»´åº¦</section></th><th><section>è¯­è¨€æ”¯æŒ</section></th><th><section>é€‚ç”¨åœºæ™¯</section></th><th><section>æ€§èƒ½</section></th></tr></thead><tbody><tr><td><strong>all-MiniLM-L6-v2</strong></td><td><section>384</section></td><td><section>è‹±æ–‡</section></td><td><section>å¿«é€ŸåŸå‹ã€æ¼”ç¤º</section></td><td><section>â­â­â­</section></td></tr><tr><td><strong>BGE-large-en-v1.5</strong></td><td><section>1024</section></td><td><section>è‹±æ–‡</section></td><td><section>ç”Ÿäº§ç¯å¢ƒã€é«˜ç²¾åº¦</section></td><td><section>â­â­â­â­â­</section></td></tr><tr><td><strong>BGE-large-zh-v1.5</strong></td><td><section>1024</section></td><td><section>ä¸­æ–‡</section></td><td><section>ä¸­æ–‡æ£€ç´¢</section></td><td><section>â­â­â­â­â­</section></td></tr><tr><td><strong>E5-mistral-7b</strong></td><td><section>4096</section></td><td><section>å¤šè¯­è¨€</section></td><td><section>é•¿æ–‡æ¡£æ£€ç´¢</section></td><td><section>â­â­â­â­</section></td></tr></tbody></table>

**ä»£ç ç¤ºä¾‹**ï¼š

```
fromÂ sentence_transformersÂ importÂ SentenceTransformer# é€‰æ‹©æ¨¡å‹ï¼ˆæ ¹æ®éœ€æ±‚ï¼‰embedding_model =Â "sentence-transformers/all-MiniLM-L6-v2"Â Â # å¿«é€Ÿï¼Œ80MB# embedding_model = "BAAI/bge-large-en-v1.5" Â # é«˜ç²¾åº¦ï¼Œ1.3GB# åŠ è½½æ¨¡å‹encoder = SentenceTransformer(embedding_model)# ç”Ÿæˆå‘é‡texts = ["Milvus is a vector database...",Â "RAG combines retrieval and generation..."]embeddings = encoder.encode(texts, normalize_embeddings=True)print(f"å‘é‡ç»´åº¦:Â {embeddings.shape}") Â # (2, 384) æˆ– (2, 1024)
```

### 3.4 åˆ›å»º Milvus é›†åˆ

åœ¨æ’å…¥æ•°æ®ä¹‹å‰ï¼Œéœ€è¦å…ˆåˆ›å»ºé›†åˆï¼ˆCollectionï¼‰ï¼š

```
fromÂ pymilvusÂ importÂ MilvusClient# è¿æ¥Milvusï¼ˆè‡ªåŠ¨ä½¿ç”¨Milvus Liteï¼‰client = MilvusClient(uri="./milvus_demo.db")# é›†åˆé…ç½®collection_name =Â "documents"dimension =Â 384# æ ¹æ®Embeddingæ¨¡å‹é€‰æ‹©ï¼šall-MiniLM-L6-v2=384, BGE-large=1024# æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨ifÂ client.has_collection(collection_name):Â  Â  print(f"é›†åˆÂ {collection_name}Â å·²å­˜åœ¨ï¼Œåˆ é™¤æ—§é›†åˆ...")Â  Â  client.drop_collection(collection_name)# åˆ›å»ºé›†åˆclient.create_collection(Â  Â  collection_, Â  Â  Â  Â Â # è·ç¦»åº¦é‡ï¼šL2ï¼ˆæ¬§æ°è·ç¦»ï¼‰æˆ–IPï¼ˆå†…ç§¯ï¼‰Â  Â  auto_id=True, Â  Â  Â  Â  Â  Â Â # è‡ªåŠ¨ç”ŸæˆID)print(f"âœ“ é›†åˆÂ {collection_name}Â åˆ›å»ºæˆåŠŸ")
```

### 3.5 æ’å…¥æ•°æ®

å°†å‘é‡å’Œå…ƒæ•°æ®æ’å…¥ Milvusï¼š

```
# å‡†å¤‡æ•°æ®documents = [Â  Â  {Â  Â  Â  Â Â "text":Â "Milvus is an open-source vector database...",Â  Â  Â  Â Â "doc_id":Â "doc_001",Â  Â  Â  Â Â "title":Â "Introduction to Milvus"Â  Â  },Â  Â Â # ... æ›´å¤šæ–‡æ¡£]# ç”Ÿæˆå‘é‡texts = [doc["text"]Â forÂ docÂ inÂ documents]embeddings = encoder.encode(texts, normalize_embeddings=True)# å‡†å¤‡æ’å…¥æ•°æ®data = []forÂ i, (emb, doc)Â inÂ enumerate(zip(embeddings, documents)):Â  Â  data.append({Â  Â  Â  Â Â "vector": emb.tolist(), Â # å‘é‡ï¼ˆå¿…é¡»ï¼‰Â  Â  Â  Â Â "text": doc["text"], Â  Â  Â # æ–‡æœ¬å†…å®¹Â  Â  Â  Â Â "doc_id": doc["doc_id"], Â # ä¸šåŠ¡IDÂ  Â  Â  Â Â "title": doc["title"], Â  Â # æ ‡é¢˜Â  Â  })# æ’å…¥æ•°æ®client.insert(collection_âœ“ æˆåŠŸæ’å…¥Â {len(data)}Â ä¸ªæ–‡æ¡£")
```

**å®Œæ•´çš„æ•°æ®å‡†å¤‡è„šæœ¬**ï¼š

```
"""å®Œæ•´çš„æ•°æ®å‡†å¤‡ç¤ºä¾‹"""fromÂ pymilvusÂ importÂ MilvusClientfromÂ sentence_transformersÂ importÂ SentenceTransformerdefÂ prepare_data():Â  Â Â # 1. è¿æ¥MilvusÂ  Â  client = MilvusClient(uri="./milvus_demo.db")Â  Â  collection_name =Â "documents"Â  Â Â # 2. å‡†å¤‡æ–‡æ¡£Â  Â  documents = [Â  Â  Â  Â Â "Milvus is an open-source vector database...",Â  Â  Â  Â Â "RAG combines information retrieval with language models...",Â  Â  Â  Â Â # ... æ›´å¤šæ–‡æ¡£Â  Â  ]Â  Â Â # 3. åˆå§‹åŒ–Embeddingæ¨¡å‹Â  Â  encoder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")Â  Â  dimension =Â 384Â  Â Â # 4. åˆ›å»ºé›†åˆÂ  Â Â ifÂ client.has_collection(collection_name):Â  Â  Â  Â  client.drop_collection(collection_name)Â  Â  client.create_collection(Â  Â  Â  Â  collection_,Â  Â  Â  Â  auto_id=True,Â  Â  )Â  Â Â # 5. ç”Ÿæˆå‘é‡å¹¶æ’å…¥Â  Â  embeddings = encoder.encode(documents, normalize_embeddings=True)Â  Â  data = [Â  Â  Â  Â  {"vector": emb.tolist(),Â "text": doc}Â  Â  Â  Â Â forÂ emb, docÂ inÂ zip(embeddings, documents)Â  Â  ]Â  Â  client.insert(collection_âœ“ æ•°æ®å‡†å¤‡å®Œæˆï¼Œå…±Â {len(data)}Â ä¸ªæ–‡æ¡£")ifÂ __name__ ==Â "__main__":Â  Â  prepare_data()
```

* * *

4. æ ¸å¿ƒå®ç°ï¼šæ„å»º RAG ç³»ç»Ÿ
-----------------

### 4.1 RAG ç³»ç»Ÿæ¶æ„

ä¸€ä¸ªå®Œæ•´çš„ RAG ç³»ç»ŸåŒ…å«ä»¥ä¸‹ç»„ä»¶ï¼š

```
ç”¨æˆ·æŸ¥è¯¢Â  Â  â†“å‘é‡æ£€ç´¢ï¼ˆMilvusï¼‰â† çŸ¥è¯†åº“Â  Â  â†“ç»“æœé‡æ’ï¼ˆå¯é€‰ï¼‰Â  Â  â†“ä¸Šä¸‹æ–‡æ„å»ºÂ  Â  â†“LLMç”Ÿæˆç­”æ¡ˆ
```

### 4.2 åŸºç¡€ RAG å®ç°

è®©æˆ‘ä»¬ä»æœ€ç®€å•çš„ RAG ç³»ç»Ÿå¼€å§‹ï¼š

```
fromÂ pymilvusÂ importÂ MilvusClientfromÂ sentence_transformersÂ importÂ SentenceTransformerclassÂ SimpleRAGSystem:Â  Â Â """åŸºç¡€RAGç³»ç»Ÿ"""Â  Â Â defÂ __init__(self, milvus_uri="./milvus_demo.db", collection_Â  Â  Â  Â Â # 1. ç¼–ç æŸ¥è¯¢Â  Â  Â  Â  query_vector = self.encoder.encode(query, normalize_embeddings=True)Â  Â  Â  Â  query_vector = query_vector.tolist()Â  Â  Â  Â Â # 2. åœ¨Milvusä¸­æœç´¢Â  Â  Â  Â  results = self.client.search(Â  Â  Â  Â  Â  Â  collection_name=self.collection_name,Â  Â  Â  Â  Â  Â  data=[query_vector],Â  Â  Â  Â  Â  Â  limit=top_k,Â  Â  Â  Â  Â  Â  search_params={"metric_type":Â "L2",Â "params": {}},Â  Â  Â  Â  Â  Â  output_fields=["text",Â "doc_id",Â "title"]Â  Â  Â  Â  )Â  Â  Â  Â Â # 3. æ ¼å¼åŒ–ç»“æœÂ  Â  Â  Â  retrieved_docs = []Â  Â  Â  Â Â forÂ hitÂ inÂ results[0]:Â  Â  Â  Â  Â  Â  retrieved_docs.append({Â  Â  Â  Â  Â  Â  Â  Â Â "id": hit.get("id",Â ""),Â  Â  Â  Â  Â  Â  Â  Â Â "text": hit.get("entity", {}).get("text",Â ""),Â  Â  Â  Â  Â  Â  Â  Â Â "score": hit.get("distance",Â 0.0),Â  Â  Â  Â  Â  Â  Â  Â Â "doc_id": hit.get("entity", {}).get("doc_id",Â ""),Â  Â  Â  Â  Â  Â  Â  Â Â "title": hit.get("entity", {}).get("title",Â ""),Â  Â  Â  Â  Â  Â  })Â  Â  Â  Â Â returnÂ retrieved_docsÂ  Â Â defÂ query(self, user_query: str, top_k: int =Â 5):Â  Â  Â  Â Â """æŸ¥è¯¢æµç¨‹"""Â  Â  Â  Â Â # 1. æ£€ç´¢Â  Â  Â  Â  retrieved_docs = self.retrieve(user_query, top_k=top_k)Â  Â  Â  Â Â # 2. æ„å»ºä¸Šä¸‹æ–‡Â  Â  Â  Â  context =Â "\n\n".join([doc["text"]Â forÂ docÂ inÂ retrieved_docs])Â  Â  Â  Â Â # 3. è¿”å›ç»“æœï¼ˆè¿™é‡Œåªè¿”å›ä¸Šä¸‹æ–‡ï¼Œå®é™…åº”ç”¨ä¸­ä¼šè°ƒç”¨LLMï¼‰Â  Â  Â  Â Â returnÂ {Â  Â  Â  Â  Â  Â Â "query": user_query,Â  Â  Â  Â  Â  Â Â "context": context,Â  Â  Â  Â  Â  Â Â "documents": retrieved_docsÂ  Â  Â  Â  }# ä½¿ç”¨ç¤ºä¾‹rag = SimpleRAGSystem()result = rag.query("What is Milvus?")print(result["context"])
```

### 4.3 å¢å¼ºç‰ˆ RAGï¼šæ·»åŠ é‡æ’

å‘é‡æ£€ç´¢è™½ç„¶å¿«é€Ÿï¼Œä½†å¯èƒ½ä¸å¤Ÿç²¾ç¡®ã€‚æˆ‘ä»¬å¯ä»¥æ·»åŠ é‡æ’ï¼ˆRerankingï¼‰æ­¥éª¤æ¥æå‡å‡†ç¡®æ€§ï¼š

```
fromÂ transformersÂ importÂ AutoModelForSequenceClassification, AutoTokenizerimportÂ torchclassÂ EnhancedRAGSystem(SimpleRAGSystem):Â  Â Â """å¢å¼ºç‰ˆRAGç³»ç»Ÿï¼ˆå¸¦é‡æ’ï¼‰"""Â  Â Â defÂ __init__(self, milvus_uri="./milvus_demo.db", collection_):Â  Â  Â  Â  super().__init__(milvus_uri, collection_name)Â  Â  Â  Â Â # åˆå§‹åŒ–é‡æ’æ¨¡å‹ï¼ˆå¯é€‰ï¼‰Â  Â  Â  Â  self.reranker =Â NoneÂ  Â  Â  Â  self.reranker_tokenizer =Â NoneÂ  Â  Â  Â Â try:Â  Â  Â  Â  Â  Â  print("æ­£åœ¨åŠ è½½é‡æ’æ¨¡å‹...")Â  Â  Â  Â  Â  Â  reranker_model =Â "BAAI/bge-reranker-base"Â  Â  Â  Â  Â  Â  self.reranker = AutoModelForSequenceClassification.from_pretrained(reranker_model)Â  Â  Â  Â  Â  Â  self.reranker_tokenizer = AutoTokenizer.from_pretrained(reranker_model)Â  Â  Â  Â  Â  Â  self.reranker.eval()Â  Â  Â  Â  Â  Â  print("âœ“ é‡æ’æ¨¡å‹åŠ è½½æˆåŠŸ")Â  Â  Â  Â Â exceptÂ ExceptionÂ asÂ e:Â  Â  Â  Â  Â  Â  print(f"âš ï¸ é‡æ’æ¨¡å‹åŠ è½½å¤±è´¥:Â {e}ï¼Œå°†è·³è¿‡é‡æ’æ­¥éª¤")Â  Â Â defÂ rerank(self, query: str, documents: List[str], top_k: int =Â 10):Â  Â  Â  Â Â """é‡æ’ï¼šä½¿ç”¨BGE-Rerankerå¯¹æ£€ç´¢ç»“æœè¿›è¡Œç²¾æ’"""Â  Â  Â  Â Â ifÂ self.rerankerÂ isNoneorÂ len(documents) ==Â 0:Â  Â  Â  Â  Â  Â Â returnÂ documents[:top_k]Â  Â  Â  Â Â # æ„å»ºæŸ¥è¯¢-æ–‡æ¡£å¯¹Â  Â  Â  Â  pairs = [[query, doc]Â forÂ docÂ inÂ documents]Â  Â  Â  Â Â # TokenizeÂ  Â  Â  Â Â withÂ torch.no_grad():Â  Â  Â  Â  Â  Â  inputs = self.reranker_tokenizer(Â  Â  Â  Â  Â  Â  Â  Â  pairs,Â  Â  Â  Â  Â  Â  Â  Â  padding=True,Â  Â  Â  Â  Â  Â  Â  Â  truncation=True,Â  Â  Â  Â  Â  Â  Â  Â  return_tensors="pt",Â  Â  Â  Â  Â  Â  Â  Â  max_length=512Â  Â  Â  Â  Â  Â  )Â  Â  Â  Â  Â  Â Â # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°Â  Â  Â  Â  Â  Â  scores = self.reranker(**inputs).logits.squeeze(-1)Â  Â  Â  Â  Â  Â Â # æŒ‰åˆ†æ•°æ’åºÂ  Â  Â  Â  Â  Â  ranked_indices = scores.argsort(descending=True)Â  Â  Â  Â  Â  Â Â # è¿”å›Top-KÂ  Â  Â  Â  Â  Â  reranked_docs = [documents[idx]Â forÂ idxÂ inÂ ranked_indices[:top_k]]Â  Â  Â  Â Â returnÂ reranked_docsÂ  Â Â defÂ query(self, user_query: str, retrieve_top_k: int =Â 100, rerank_top_k: int =Â 10):Â  Â  Â  Â Â """æŸ¥è¯¢æµç¨‹ï¼šæ£€ç´¢ â†’ é‡æ’ â†’ æ„å»ºä¸Šä¸‹æ–‡"""Â  Â  Â  Â Â # 1. å‘é‡æ£€ç´¢ï¼ˆç²—æ’ï¼‰Â  Â  Â  Â  retrieved_docs = self.retrieve(user_query, top_k=retrieve_top_k)Â  Â  Â  Â Â # 2. é‡æ’ï¼ˆç²¾æ’ï¼‰Â  Â  Â  Â  doc_texts = [doc["text"]Â forÂ docÂ inÂ retrieved_docs]Â  Â  Â  Â  reranked_texts = self.rerank(user_query, doc_texts, top_k=rerank_top_k)Â  Â  Â  Â Â # 3. æ„å»ºä¸Šä¸‹æ–‡Â  Â  Â  Â  context =Â "\n\n".join(reranked_texts)Â  Â  Â  Â Â returnÂ {Â  Â  Â  Â  Â  Â Â "query": user_query,Â  Â  Â  Â  Â  Â Â "context": context,Â  Â  Â  Â  Â  Â Â "retrieved_count": len(retrieved_docs),Â  Â  Â  Â  Â  Â Â "reranked_count": len(reranked_texts)Â  Â  Â  Â  }
```

**é‡æ’çš„ä¼˜åŠ¿**ï¼š

*   **æå‡å‡†ç¡®æ€§**ï¼šé‡æ’æ¨¡å‹è€ƒè™‘æŸ¥è¯¢å’Œæ–‡æ¡£çš„äº¤äº’ï¼Œæ¯”å•çº¯å‘é‡ç›¸ä¼¼åº¦æ›´å‡†ç¡®
    
*   **çµæ´»è°ƒæ•´**ï¼šå¯ä»¥è°ƒæ•´é‡æ’åçš„ Top-Kï¼Œå¹³è¡¡å‡†ç¡®æ€§å’Œæˆæœ¬
    
*   **æ•ˆæœæ˜¾è‘—**ï¼šé€šå¸¸èƒ½æå‡ 15-22% çš„å‡†ç¡®ç‡
    

* * *

5. å…³é”®ä¼˜åŒ–ï¼šçªç ´ U å‹é™·é˜±
----------------

### 5.1 ä»€ä¹ˆæ˜¯ U å‹é™·é˜±ï¼Ÿ

ç ”ç©¶å‘ç°ï¼Œé•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹å­˜åœ¨**ä½ç½®åå·®**ï¼ˆPosition Biasï¼‰ï¼š

*   **å¼€å¤´ä½ç½®**ï¼ˆPrimacy Biasï¼‰ï¼šå‡†ç¡®ç‡ ~75.8% âœ…
    
*   **ä¸­é—´ä½ç½®**ï¼ˆLost in the Middleï¼‰ï¼šå‡†ç¡®ç‡ ~53.8% âŒ
    
*   **ç»“å°¾ä½ç½®**ï¼ˆRecency Biasï¼‰ï¼šå‡†ç¡®ç‡ ~63.2% âœ…
    

è¿™æ„å‘³ç€ï¼Œå¦‚æœå…³é”®ä¿¡æ¯æ”¾åœ¨ä¸­é—´ä½ç½®ï¼Œæ¨¡å‹å¯èƒ½æ— æ³•æœ‰æ•ˆåˆ©ç”¨ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

### 5.2 ä½ç½®ä¼˜åŒ–ç­–ç•¥

é€šè¿‡**ä½ç½®ä¼˜åŒ–**ï¼Œæˆ‘ä»¬å¯ä»¥çªç ´ U å‹é™·é˜±ï¼š

**æ ¸å¿ƒç­–ç•¥**ï¼š

1.  **æœ€ç›¸å…³æ–‡æ¡£ â†’ å¼€å¤´**ï¼šåˆ©ç”¨ Primacy Bias
    
2.  **æ¬¡ç›¸å…³æ–‡æ¡£ â†’ ä¸­é—´**ï¼šä½ä¼˜å…ˆçº§
    
3.  **ç”¨æˆ·é—®é¢˜ â†’ ç»“å°¾**ï¼šåˆ©ç”¨ Recency Bias
    

### 5.3 å®ç°ä½ç½®ä¼˜åŒ–

```
classÂ OptimizedRAGSystem(EnhancedRAGSystem):Â  Â Â """ä¼˜åŒ–ç‰ˆRAGç³»ç»Ÿï¼ˆä½ç½®ä¼˜åŒ–ï¼‰"""Â  Â Â defÂ build_context(self, query: str, retrieved_docs: List[Dict[str, Any]])Â -> str:Â  Â  Â  Â Â """Â  Â  Â  Â  æ„å»ºä¸Šä¸‹æ–‡ï¼ˆä½ç½®ä¼˜åŒ–ï¼šçªç ´Uå‹é™·é˜±çš„å…³é”®æ­¥éª¤ï¼‰Â  Â  Â  Â  ç­–ç•¥ï¼šÂ  Â  Â  Â  - æœ€ç›¸å…³æ–‡æ¡£ â†’ å¼€å¤´ï¼ˆåˆ©ç”¨Primacy Biasï¼‰Â  Â  Â  Â  - æ¬¡ç›¸å…³æ–‡æ¡£ â†’ ä¸­é—´ï¼ˆä½ä¼˜å…ˆçº§ï¼‰Â  Â  Â  Â  - ç”¨æˆ·é—®é¢˜ â†’ ç»“å°¾ï¼ˆåˆ©ç”¨Recency Biasï¼‰Â  Â  Â  Â  """Â  Â  Â  Â Â ifÂ len(retrieved_docs) ==Â 0:Â  Â  Â  Â  Â  Â Â returnf"ç³»ç»Ÿæç¤ºï¼šè¯·å›ç­”é—®é¢˜ã€‚\n\nç”¨æˆ·é—®é¢˜ï¼š{query}"Â  Â  Â  Â Â # æŒ‰ç›¸å…³æ€§æ’åºï¼ˆæœ€ç›¸å…³çš„åœ¨å‰ï¼‰Â  Â  Â  Â  sorted_docs = sorted(Â  Â  Â  Â  Â  Â  retrieved_docs,Â  Â  Â  Â  Â  Â  key=lambdaÂ x: x.get("score",Â 0)Â ifÂ isinstance(x.get("score"), (int, float))Â else0,Â  Â  Â  Â  Â  Â  reverse=True# åˆ†æ•°è¶Šé«˜è¶Šå¥½ï¼ˆå¦‚æœæ˜¯ç›¸ä¼¼åº¦åˆ†æ•°ï¼‰Â  Â  Â  Â  )Â  Â  Â  Â Â # æ„å»ºä¸Šä¸‹æ–‡Â  Â  Â  Â  context_parts = []Â  Â  Â  Â Â # ç³»ç»Ÿæç¤ºÂ  Â  Â  Â  context_parts.append("ç³»ç»Ÿæç¤ºï¼šè¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”é—®é¢˜ã€‚\n")Â  Â  Â  Â Â # æœ€ç›¸å…³æ–‡æ¡£ï¼ˆå¼€å¤´ä½ç½® - åˆ©ç”¨Primacy Biasï¼‰Â  Â  Â  Â  context_parts.append("# æœ€ç›¸å…³æ–‡æ¡£ï¼ˆå¼€å¤´ä½ç½®ï¼‰\n")Â  Â  Â  Â  top_docs = sorted_docs[:min(3, len(sorted_docs))]Â  Â  Â  Â Â forÂ i, docÂ inÂ enumerate(top_docs,Â 1):Â  Â  Â  Â  Â  Â  text = doc.get("text",Â "")Â  Â  Â  Â  Â  Â  context_parts.append(f"æ–‡æ¡£Â {i}ï¼š{text}\n")Â  Â  Â  Â Â # æ¬¡ç›¸å…³æ–‡æ¡£ï¼ˆä¸­é—´ä½ç½®ï¼‰Â  Â  Â  Â Â ifÂ len(sorted_docs) >Â 3:Â  Â  Â  Â  Â  Â  context_parts.append("\n# æ¬¡ç›¸å…³æ–‡æ¡£ï¼ˆä¸­é—´ä½ç½®ï¼‰\n")Â  Â  Â  Â  Â  Â  secondary_docs = sorted_docs[3:min(7, len(sorted_docs))]Â  Â  Â  Â  Â  Â Â forÂ i, docÂ inÂ enumerate(secondary_docs,Â 4):Â  Â  Â  Â  Â  Â  Â  Â  text = doc.get("text",Â "")Â  Â  Â  Â  Â  Â  Â  Â  context_parts.append(f"æ–‡æ¡£Â {i}ï¼š{text}\n")Â  Â  Â  Â Â # ç”¨æˆ·é—®é¢˜ï¼ˆç»“å°¾ä½ç½® - åˆ©ç”¨Recency Biasï¼‰Â  Â  Â  Â  context_parts.append("\n# ç”¨æˆ·é—®é¢˜ï¼ˆç»“å°¾ä½ç½®ï¼‰\n")Â  Â  Â  Â  context_parts.append(f"ç”¨æˆ·é—®é¢˜ï¼š{query}")Â  Â  Â  Â Â return"\n".join(context_parts)Â  Â Â defÂ query(self, user_query: str, retrieve_top_k: int =Â 100, rerank_top_k: int =Â 10):Â  Â  Â  Â Â """å®Œæ•´æŸ¥è¯¢æµç¨‹ï¼šæ£€ç´¢ â†’ é‡æ’ â†’ ä½ç½®ä¼˜åŒ– â†’ ç”Ÿæˆ"""Â  Â  Â  Â  print(f"\næŸ¥è¯¢ï¼š{user_query}\n")Â  Â  Â  Â Â # 1. å‘é‡æ£€ç´¢Â  Â  Â  Â  print(f"æ­¥éª¤ 1: å‘é‡æ£€ç´¢ï¼ˆTop-{retrieve_top_k}ï¼‰...")Â  Â  Â  Â  retrieved_docs = self.retrieve(user_query, top_k=retrieve_top_k)Â  Â  Â  Â  print(f"âœ“ æ£€ç´¢åˆ°Â {len(retrieved_docs)}Â ä¸ªæ–‡æ¡£")Â  Â  Â  Â Â ifÂ len(retrieved_docs) ==Â 0:Â  Â  Â  Â  Â  Â Â returnÂ {"query": user_query,Â "context":Â "",Â "answer":Â "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚"}Â  Â  Â  Â Â # 2. é‡æ’ï¼ˆå¯é€‰ï¼‰Â  Â  Â  Â Â ifÂ self.rerankerÂ isnotNone:Â  Â  Â  Â  Â  Â  print(f"\næ­¥éª¤ 2: é‡æ’ï¼ˆTop-{rerank_top_k}ï¼‰...")Â  Â  Â  Â  Â  Â  doc_texts = [doc["text"]Â forÂ docÂ inÂ retrieved_docs]Â  Â  Â  Â  Â  Â  reranked_texts = self.rerank(user_query, doc_texts, top_k=rerank_top_k)Â  Â  Â  Â  Â  Â Â # æ›´æ–°æ–‡æ¡£åˆ—è¡¨ï¼ˆåªä¿ç•™é‡æ’åçš„æ–‡æ¡£ï¼‰Â  Â  Â  Â  Â  Â  reranked_docs = [Â  Â  Â  Â  Â  Â  Â  Â  docÂ forÂ docÂ inÂ retrieved_docsÂ  Â  Â  Â  Â  Â  Â  Â Â ifÂ doc["text"]Â inÂ reranked_textsÂ  Â  Â  Â  Â  Â  ]Â  Â  Â  Â  Â  Â Â # æŒ‰é‡æ’é¡ºåºé‡æ–°æ’åºÂ  Â  Â  Â  Â  Â  text_to_doc = {doc["text"]: docÂ forÂ docÂ inÂ reranked_docs}Â  Â  Â  Â  Â  Â  reranked_docs = [text_to_doc[text]Â forÂ textÂ inÂ reranked_texts]Â  Â  Â  Â  Â  Â  print(f"âœ“ é‡æ’å®Œæˆï¼Œè¿”å› Top-{len(reranked_docs)}Â ä¸ªæ–‡æ¡£")Â  Â  Â  Â Â else:Â  Â  Â  Â  Â  Â  print(f"\næ­¥éª¤ 2: è·³è¿‡é‡æ’ï¼ˆæœªé…ç½®Rerankerï¼‰...")Â  Â  Â  Â  Â  Â  reranked_docs = retrieved_docs[:rerank_top_k]Â  Â  Â  Â  Â  Â  print(f"âœ“ ä½¿ç”¨æ£€ç´¢ç»“æœï¼Œè¿”å› Top-{len(reranked_docs)}Â ä¸ªæ–‡æ¡£")Â  Â  Â  Â Â # 3. ä½ç½®ä¼˜åŒ–æ„å»ºä¸Šä¸‹æ–‡Â  Â  Â  Â  print(f"\næ­¥éª¤ 3: ä½ç½®ä¼˜åŒ–æ„å»ºä¸Šä¸‹æ–‡...")Â  Â  Â  Â  context = self.build_context(user_query, reranked_docs)Â  Â  Â  Â  print(f"âœ“ ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆï¼ˆé•¿åº¦ï¼š{len(context)}Â å­—ç¬¦ï¼‰")Â  Â  Â  Â Â # 4. ç”Ÿæˆç­”æ¡ˆï¼ˆè¿™é‡Œåªè¿”å›ä¸Šä¸‹æ–‡ï¼Œå®é™…åº”ç”¨ä¸­ä¼šè°ƒç”¨LLMï¼‰Â  Â  Â  Â  print(f"\næ­¥éª¤ 4: ä¸Šä¸‹æ–‡å·²å‡†å¤‡å°±ç»ª\n")Â  Â  Â  Â Â returnÂ {Â  Â  Â  Â  Â  Â Â "query": user_query,Â  Â  Â  Â  Â  Â Â "retrieved_docs": retrieved_docs[:5], Â # åªè¿”å›å‰5ä¸ªç”¨äºå±•ç¤ºÂ  Â  Â  Â  Â  Â Â "reranked_docs": reranked_docs,Â  Â  Â  Â  Â  Â Â "context": context,Â  Â  Â  Â  Â  Â Â "answer":Â "ã€æç¤ºã€‘æœªé…ç½®LLMï¼Œä»…è¿”å›ä¸Šä¸‹æ–‡ã€‚\n\n"Â + contextÂ  Â  Â  Â  }
```

### 5.4 æ•ˆæœå¯¹æ¯”

ä½ç½®ä¼˜åŒ–å¸¦æ¥çš„æ•ˆæœæå‡ï¼š

<table><thead><tr><th><section>æŒ‡æ ‡</section></th><th><section>ä¼˜åŒ–å‰ï¼ˆä¸­é—´ä½ç½®ï¼‰</section></th><th><section>ä¼˜åŒ–åï¼ˆå¼€å¤´ä½ç½®ï¼‰</section></th><th><section>æå‡</section></th></tr></thead><tbody><tr><td><strong>å‡†ç¡®ç‡</strong></td><td><section>53.8%</section></td><td><section>75.8%</section></td><td><strong>+22%</strong></td></tr><tr><td><strong>ä¿¡æ¯åˆ©ç”¨ç‡</strong></td><td><section>ä½</section></td><td><section>é«˜</section></td><td><section>æ˜¾è‘—æå‡</section></td></tr></tbody></table>

**å…³é”®ç»“è®º**ï¼šä½ç½®ä¼˜åŒ–æ˜¯çªç ´ U å‹é™·é˜±çš„æ ¸å¿ƒæ­¥éª¤ï¼Œç”Ÿäº§ç¯å¢ƒå¿…é¡»åŒ…å«ï¼

* * *

6. æ€§èƒ½ä¼˜åŒ–å®æˆ˜
---------

### 6.1 ç´¢å¼•é€‰æ‹©

Milvus æ”¯æŒå¤šç§ç´¢å¼•ç±»å‹ï¼Œé€‰æ‹©åˆé€‚çš„ç´¢å¼•å¯¹æ€§èƒ½è‡³å…³é‡è¦ï¼š

<table><thead><tr><th><section>ç´¢å¼•ç±»å‹</section></th><th><section>ç‰¹ç‚¹</section></th><th><section>é€‚ç”¨åœºæ™¯</section></th><th><section>æ¨èå‚æ•°</section></th></tr></thead><tbody><tr><td><strong>HNSW</strong></td><td><section>é«˜ç²¾åº¦ã€ä½å»¶è¿Ÿ</section></td><td><section>é«˜ç²¾åº¦è¦æ±‚ã€ä½å»¶è¿Ÿéœ€æ±‚</section></td><td><section>M=16, ef=64</section></td></tr><tr><td><strong>IVF_FLAT</strong></td><td><section>æˆæœ¬å‹å¥½</section></td><td><section>å¤§è§„æ¨¡æ•°æ®ã€æˆæœ¬æ•æ„Ÿ</section></td><td><section>nlist=1024, nprobe=10</section></td></tr><tr><td><strong>IVF_PQ</strong></td><td><section>å‹ç¼©å­˜å‚¨</section></td><td><section>è¶…å¤§è§„æ¨¡æ•°æ®</section></td><td><section>nlist=1024, m=8</section></td></tr><tr><td><strong>DiskANN</strong></td><td><section>å¤§è§„æ¨¡åœºæ™¯</section></td><td><section>ç™¾äº¿çº§å‘é‡</section></td><td><section>é€‚åˆç£ç›˜å­˜å‚¨</section></td></tr></tbody></table>

**ä»£ç ç¤ºä¾‹**ï¼ˆä½¿ç”¨ HNSW ç´¢å¼•ï¼‰ï¼š

```
# æ³¨æ„ï¼šMilvusClientæ–¹å¼åˆ›å»ºé›†åˆæ—¶ï¼Œç´¢å¼•å‚æ•°åœ¨create_collectionä¸­è®¾ç½®# å¦‚æœéœ€è¦æ›´ç²¾ç»†çš„ç´¢å¼•æ§åˆ¶ï¼Œå¯ä»¥ä½¿ç”¨pymilvusçš„Collectionæ–¹å¼fromÂ pymilvusÂ importÂ Collection, connections, FieldSchema, CollectionSchema, DataType# è¿æ¥Milvus Serverï¼ˆä¸æ˜¯Liteï¼‰connections.connect(alias="default", host="localhost", port="19530")# å®šä¹‰Schemafields = [Â  Â  FieldSchema(, dtype=DataType.VARCHAR, max_length=1000),]schema = CollectionSchema(fields=fields, description="Documents collection")collection = Collection(, schema=schema)# åˆ›å»ºHNSWç´¢å¼•index_params = {Â  Â Â "metric_type":Â "L2",Â  Â Â "index_type":Â "HNSW",Â  Â Â "params": {Â  Â  Â  Â Â "M":Â 16, Â  Â  Â  Â  Â  Â  Â # æ¯ä¸ªèŠ‚ç‚¹çš„è¿æ¥æ•°Â  Â  Â  Â Â "efConstruction":Â 200# æ„å»ºæ—¶çš„æœç´¢èŒƒå›´Â  Â  }}collection.create_index(field_, index_params=index_params)# æœç´¢æ—¶è®¾ç½®efå‚æ•°search_params = {"metric_type":Â "L2",Â "params": {"ef":Â 64}}
```

### 6.2 æ‰¹é‡å¤„ç†

å¯¹äºå¤§é‡æŸ¥è¯¢ï¼Œä½¿ç”¨æ‰¹é‡å¤„ç†å¯ä»¥æ˜¾è‘—æå‡ååé‡ï¼š

```
defÂ batch_search(self, queries: List[str], batch_size: int =Â 32):Â  Â Â """æ‰¹é‡æ£€ç´¢"""Â  Â  all_results = []Â  Â Â # æ‰¹é‡ç¼–ç Â  Â  query_vectors = self.encoder.encode(queries, normalize_embeddings=True)Â  Â Â # æ‰¹é‡æœç´¢Â  Â Â forÂ iÂ inÂ range(0, len(query_vectors), batch_size):Â  Â  Â  Â  batch_vectors = query_vectors[i:i+batch_size]Â  Â  Â  Â  batch_queries = queries[i:i+batch_size]Â  Â  Â  Â  results = self.client.search(Â  Â  Â  Â  Â  Â  collection_name=self.collection_name,Â  Â  Â  Â  Â  Â  data=batch_vectors.tolist(),Â  Â  Â  Â  Â  Â  limit=10,Â  Â  Â  Â  Â  Â  search_params={"metric_type":Â "L2",Â "params": {}},Â  Â  Â  Â  Â  Â  output_fields=["text"]Â  Â  Â  Â  )Â  Â  Â  Â  all_results.extend(results)Â  Â Â returnÂ all_results
```

### 6.3 ç¼“å­˜ç­–ç•¥

å®ç°æŸ¥è¯¢ç¼“å­˜å¯ä»¥å¤§å¹…é™ä½å»¶è¿Ÿå’Œæˆæœ¬ï¼š

```
fromÂ functoolsÂ importÂ lru_cacheimportÂ hashlibimportÂ jsonclassÂ CachedRAGSystem(OptimizedRAGSystem):Â  Â Â """å¸¦ç¼“å­˜çš„RAGç³»ç»Ÿ"""Â  Â Â defÂ __init__(self, *args, **kwargs):Â  Â  Â  Â  super().__init__(*args, **kwargs)Â  Â  Â  Â  self.cache = {} Â # ç®€å•çš„å†…å­˜ç¼“å­˜ï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨RedisÂ  Â Â defÂ _get_cache_key(self, query: str, top_k: int)Â -> str:Â  Â  Â  Â Â """ç”Ÿæˆç¼“å­˜é”®"""Â  Â  Â  Â  key_data =Â f"{query}_{top_k}"Â  Â  Â  Â Â returnÂ hashlib.md5(key_data.encode()).hexdigest()Â  Â Â defÂ retrieve(self, query: str, top_k: int =Â 10, use_cache: bool = True):Â  Â  Â  Â Â """å¸¦ç¼“å­˜çš„æ£€ç´¢"""Â  Â  Â  Â Â ifÂ use_cache:Â  Â  Â  Â  Â  Â  cache_key = self._get_cache_key(query, top_k)Â  Â  Â  Â  Â  Â Â ifÂ cache_keyÂ inÂ self.cache:Â  Â  Â  Â  Â  Â  Â  Â  print(f"âœ“ ä½¿ç”¨ç¼“å­˜ç»“æœ")Â  Â  Â  Â  Â  Â  Â  Â Â returnÂ self.cache[cache_key]Â  Â  Â  Â Â # æ‰§è¡Œæ£€ç´¢Â  Â  Â  Â  results = super().retrieve(query, top_k)Â  Â  Â  Â Â # å­˜å…¥ç¼“å­˜Â  Â  Â  Â Â ifÂ use_cache:Â  Â  Â  Â  Â  Â  self.cache[cache_key] = resultsÂ  Â  Â  Â Â returnÂ results
```

### 6.4 å¼‚æ­¥å¤„ç†

å¯¹äºé«˜å¹¶å‘åœºæ™¯ï¼Œä½¿ç”¨å¼‚æ­¥å¤„ç†å¯ä»¥æå‡æ€§èƒ½ï¼š

```
importÂ asynciofromÂ concurrent.futuresÂ importÂ ThreadPoolExecutorclassÂ AsyncRAGSystem(OptimizedRAGSystem):Â  Â Â """å¼‚æ­¥RAGç³»ç»Ÿ"""Â  Â Â defÂ __init__(self, *args, **kwargs):Â  Â  Â  Â  super().__init__(*args, **kwargs)Â  Â  Â  Â  self.executor = ThreadPoolExecutor(max_workers=4)Â  Â Â asyncdefÂ async_retrieve(self, query: str, top_k: int =Â 10):Â  Â  Â  Â Â """å¼‚æ­¥æ£€ç´¢"""Â  Â  Â  Â  loop = asyncio.get_event_loop()Â  Â  Â  Â  results =Â awaitÂ loop.run_in_executor(Â  Â  Â  Â  Â  Â  self.executor,Â  Â  Â  Â  Â  Â  self.retrieve,Â  Â  Â  Â  Â  Â  query,Â  Â  Â  Â  Â  Â  top_kÂ  Â  Â  Â  )Â  Â  Â  Â Â returnÂ resultsÂ  Â Â asyncdefÂ async_query(self, user_query: str, retrieve_top_k: int =Â 100, rerank_top_k: int =Â 10):Â  Â  Â  Â Â """å¼‚æ­¥æŸ¥è¯¢"""Â  Â  Â  Â Â # å¼‚æ­¥æ£€ç´¢Â  Â  Â  Â  retrieved_docs =Â awaitÂ self.async_retrieve(user_query, top_k=retrieve_top_k)Â  Â  Â  Â Â # å…¶ä»–æ­¥éª¤å¯ä»¥ç»§ç»­å¼‚æ­¥åŒ–...Â  Â  Â  Â Â # è¿™é‡Œç®€åŒ–å¤„ç†Â  Â  Â  Â Â returnÂ {Â  Â  Â  Â  Â  Â Â "query": user_query,Â  Â  Â  Â  Â  Â Â "documents": retrieved_docsÂ  Â  Â  Â  }# ä½¿ç”¨ç¤ºä¾‹asyncdefÂ main():Â  Â  rag = AsyncRAGSystem()Â  Â  result =Â awaitÂ rag.async_query("What is Milvus?")Â  Â  print(result)# asyncio.run(main())
```

* * *

7. ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ
-----------

### 7.1 é”™è¯¯å¤„ç†ä¸é‡è¯•

ç”Ÿäº§ç¯å¢ƒå¿…é¡»åŒ…å«å®Œå–„çš„é”™è¯¯å¤„ç†ï¼š

```
importÂ timefromÂ typingÂ importÂ OptionalclassÂ ProductionRAGSystem(OptimizedRAGSystem):Â  Â Â """ç”Ÿäº§ç¯å¢ƒRAGç³»ç»Ÿï¼ˆå¸¦é”™è¯¯å¤„ç†å’Œé‡è¯•ï¼‰"""Â  Â Â defÂ retrieve_with_retry(Â  Â  Â  Â  self,Â  Â  Â  Â  query: str,Â  Â  Â  Â  top_k: int =Â 10,Â  Â  Â  Â  max_retries: int =Â 3,Â  Â  Â  Â  retry_delay: float =Â 1.0Â  Â  ):Â  Â  Â  Â Â """å¸¦é‡è¯•çš„æ£€ç´¢"""Â  Â  Â  Â Â forÂ attemptÂ inÂ range(max_retries):Â  Â  Â  Â  Â  Â Â try:Â  Â  Â  Â  Â  Â  Â  Â Â returnÂ self.retrieve(query, top_k)Â  Â  Â  Â  Â  Â Â exceptÂ ExceptionÂ asÂ e:Â  Â  Â  Â  Â  Â  Â  Â Â ifÂ attempt == max_retries -Â 1:Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â raise# æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸Â  Â  Â  Â  Â  Â  Â  Â  print(f"æ£€ç´¢å¤±è´¥ï¼ˆå°è¯•Â {attempt +Â 1}/{max_retries}ï¼‰ï¼š{e}")Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(retry_delay * (attempt +Â 1)) Â # æŒ‡æ•°é€€é¿Â  Â  Â  Â Â returnÂ []Â  Â Â defÂ query(self, user_query: str, **kwargs):Â  Â  Â  Â Â """ç”Ÿäº§ç¯å¢ƒæŸ¥è¯¢ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰"""Â  Â  Â  Â Â try:Â  Â  Â  Â  Â  Â Â returnÂ super().query(user_query, **kwargs)Â  Â  Â  Â Â exceptÂ ExceptionÂ asÂ e:Â  Â  Â  Â  Â  Â Â returnÂ {Â  Â  Â  Â  Â  Â  Â  Â Â "query": user_query,Â  Â  Â  Â  Â  Â  Â  Â Â "error": str(e),Â  Â  Â  Â  Â  Â  Â  Â Â "context":Â "",Â  Â  Â  Â  Â  Â  Â  Â Â "answer":Â "æŠ±æ­‰ï¼ŒæŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"Â  Â  Â  Â  Â  Â  }
```

### 7.2 æ—¥å¿—è®°å½•

æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è®°å½•ï¼Œä¾¿äºç›‘æ§å’Œè°ƒè¯•ï¼š

```
importÂ loggingfromÂ datetimeÂ importÂ datetimeclassÂ LoggedRAGSystem(ProductionRAGSystem):Â  Â Â """å¸¦æ—¥å¿—çš„RAGç³»ç»Ÿ"""Â  Â Â defÂ __init__(self, *args, **kwargs):Â  Â  Â  Â  super().__init__(*args, **kwargs)Â  Â  Â  Â Â # é…ç½®æ—¥å¿—Â  Â  Â  Â  logging.basicConfig(Â  Â  Â  Â  Â  Â  level=logging.INFO,Â  Â  Â  Â  Â  Â  format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',Â  Â  Â  Â  Â  Â  handlers=[Â  Â  Â  Â  Â  Â  Â  Â  logging.FileHandler('rag_system.log'),Â  Â  Â  Â  Â  Â  Â  Â  logging.StreamHandler()Â  Â  Â  Â  Â  Â  ]Â  Â  Â  Â  )Â  Â  Â  Â  self.logger = logging.getLogger(__name__)Â  Â Â defÂ query(self, user_query: str, **kwargs):Â  Â  Â  Â Â """å¸¦æ—¥å¿—çš„æŸ¥è¯¢"""Â  Â  Â  Â  start_time = datetime.now()Â  Â  Â  Â  self.logger.info(f"å¼€å§‹æŸ¥è¯¢:Â {user_query}")Â  Â  Â  Â Â try:Â  Â  Â  Â  Â  Â  result = super().query(user_query, **kwargs)Â  Â  Â  Â  Â  Â  elapsed_time = (datetime.now() - start_time).total_seconds()Â  Â  Â  Â  Â  Â  self.logger.info(Â  Â  Â  Â  Â  Â  Â  Â Â f"æŸ¥è¯¢å®Œæˆ:Â {user_query}, "Â  Â  Â  Â  Â  Â  Â  Â Â f"è€—æ—¶:Â {elapsed_time:.2f}ç§’, "Â  Â  Â  Â  Â  Â  Â  Â Â f"æ£€ç´¢åˆ°:Â {len(result.get('retrieved_docs', []))}Â ä¸ªæ–‡æ¡£"Â  Â  Â  Â  Â  Â  )Â  Â  Â  Â  Â  Â Â returnÂ resultÂ  Â  Â  Â Â exceptÂ ExceptionÂ asÂ e:Â  Â  Â  Â  Â  Â  self.logger.error(f"æŸ¥è¯¢å¤±è´¥:Â {user_query}, é”™è¯¯:Â {e}")Â  Â  Â  Â  Â  Â Â raise
```

### 7.3 ç›‘æ§æŒ‡æ ‡

æ”¶é›†å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼š

```
fromÂ collectionsÂ importÂ defaultdictimportÂ timeclassÂ MonitoredRAGSystem(LoggedRAGSystem):Â  Â Â """å¸¦ç›‘æ§çš„RAGç³»ç»Ÿ"""Â  Â Â defÂ __init__(self, *args, **kwargs):Â  Â  Â  Â  super().__init__(*args, **kwargs)Â  Â  Â  Â  self.metrics = {Â  Â  Â  Â  Â  Â Â "total_queries":Â 0,Â  Â  Â  Â  Â  Â Â "total_retrieval_time":Â 0,Â  Â  Â  Â  Â  Â Â "total_rerank_time":Â 0,Â  Â  Â  Â  Â  Â Â "total_query_time":Â 0,Â  Â  Â  Â  Â  Â Â "errors":Â 0,Â  Â  Â  Â  }Â  Â Â defÂ query(self, user_query: str, **kwargs):Â  Â  Â  Â Â """å¸¦ç›‘æ§çš„æŸ¥è¯¢"""Â  Â  Â  Â  self.metrics["total_queries"] +=Â 1Â  Â  Â  Â  start_time = time.time()Â  Â  Â  Â Â try:Â  Â  Â  Â  Â  Â Â # ç›‘æ§æ£€ç´¢æ—¶é—´Â  Â  Â  Â  Â  Â  retrieval_start = time.time()Â  Â  Â  Â  Â  Â  retrieved_docs = self.retrieve(user_query, top_k=kwargs.get("retrieve_top_k",Â 100))Â  Â  Â  Â  Â  Â  self.metrics["total_retrieval_time"] += time.time() - retrieval_startÂ  Â  Â  Â  Â  Â Â # ç›‘æ§é‡æ’æ—¶é—´Â  Â  Â  Â  Â  Â Â ifÂ self.reranker:Â  Â  Â  Â  Â  Â  Â  Â  rerank_start = time.time()Â  Â  Â  Â  Â  Â  Â  Â Â # ... é‡æ’é€»è¾‘Â  Â  Â  Â  Â  Â  Â  Â  self.metrics["total_rerank_time"] += time.time() - rerank_startÂ  Â  Â  Â  Â  Â  result = super().query(user_query, **kwargs)Â  Â  Â  Â  Â  Â  self.metrics["total_query_time"] += time.time() - start_timeÂ  Â  Â  Â  Â  Â Â returnÂ resultÂ  Â  Â  Â Â exceptÂ ExceptionÂ asÂ e:Â  Â  Â  Â  Â  Â  self.metrics["errors"] +=Â 1Â  Â  Â  Â  Â  Â Â raiseÂ  Â Â defÂ get_metrics(self):Â  Â  Â  Â Â """è·å–ç›‘æ§æŒ‡æ ‡"""Â  Â  Â  Â  total = self.metrics["total_queries"]Â  Â  Â  Â Â ifÂ total ==Â 0:Â  Â  Â  Â  Â  Â Â returnÂ {}Â  Â  Â  Â Â returnÂ {Â  Â  Â  Â  Â  Â Â "total_queries": total,Â  Â  Â  Â  Â  Â Â "avg_retrieval_time": self.metrics["total_retrieval_time"] / total,Â  Â  Â  Â  Â  Â Â "avg_rerank_time": self.metrics["total_rerank_time"] / total,Â  Â  Â  Â  Â  Â Â "avg_query_time": self.metrics["total_query_time"] / total,Â  Â  Â  Â  Â  Â Â "error_rate": self.metrics["errors"] / total,Â  Â  Â  Â  }
```

### 7.4 é…ç½®ç®¡ç†

ä½¿ç”¨é…ç½®æ–‡ä»¶ç®¡ç†å‚æ•°ï¼š

```
# config.yamlmilvus:uri:"./milvus_demo.db"collection_name:"documents"embedding:model:"sentence-transformers/all-MiniLM-L6-v2"dimension:384reranker:enabled:truemodel:"BAAI/bge-reranker-base"retrieval:top_k:100rerank_top_k:10position_optimization:enabled:truetop_relevant:3secondary_relevant:5
```

```
importÂ yamlclassÂ ConfigurableRAGSystem(OptimizedRAGSystem):Â  Â Â """å¯é…ç½®çš„RAGç³»ç»Ÿ"""Â  Â Â defÂ __init__(self, config_path: str =Â "config.yaml"):Â  Â  Â  Â Â # åŠ è½½é…ç½®Â  Â  Â  Â Â withÂ open(config_path,Â 'r')Â asÂ f:Â  Â  Â  Â  Â  Â  config = yaml.safe_load(f)Â  Â  Â  Â Â # ä½¿ç”¨é…ç½®åˆå§‹åŒ–Â  Â  Â  Â  super().__init__(Â  Â  Â  Â  Â  Â  milvus_uri=config["milvus"]["uri"],Â  Â  Â  Â  Â  Â  collection_name=config["milvus"]["collection_name"]Â  Â  Â  Â  )Â  Â  Â  Â  self.config = config
```

* * *

8. å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ
------------

### 8.1 é›†åˆä¸å­˜åœ¨

**é—®é¢˜**ï¼š`Collection 'documents' does not exist`

**è§£å†³æ–¹æ¡ˆ**ï¼š

```
# æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨ifÂ notÂ client.has_collection(collection_name):Â  Â  print(f"é›†åˆÂ {collection_name}Â ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºé›†åˆå¹¶æ’å…¥æ•°æ®")Â  Â Â # åˆ›å»ºé›†åˆÂ  Â  client.create_collection(...)Â  Â Â # æ’å…¥æ•°æ®Â  Â  client.insert(...)
```

### 8.2 å‘é‡ç»´åº¦ä¸åŒ¹é…

**é—®é¢˜**ï¼š`Dimension mismatch: expected 384, got 1024`

**è§£å†³æ–¹æ¡ˆ**ï¼š

```
# ç¡®ä¿Embeddingæ¨¡å‹ç»´åº¦ä¸é›†åˆç»´åº¦ä¸€è‡´embedding_model =Â "sentence-transformers/all-MiniLM-L6-v2"Â Â # 384ç»´# æˆ–embedding_model =Â "BAAI/bge-large-en-v1.5"Â Â # 1024ç»´# åˆ›å»ºé›†åˆæ—¶ä½¿ç”¨æ­£ç¡®çš„ç»´åº¦dimension =Â 384Â ifÂ "all-MiniLM-L6-v2"Â inÂ embedding_modelÂ elseÂ 1024client.create_collection(..., dimension=dimension)
```

### 8.3 å†…å­˜ä¸è¶³

**é—®é¢˜**ï¼šåŠ è½½å¤§æ¨¡å‹æ—¶å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š

1.  **ä½¿ç”¨æ›´å°çš„æ¨¡å‹**ï¼š
    
    ```
    # ä½¿ç”¨å°æ¨¡å‹ï¼ˆ80MB vs 1.3GBï¼‰encoder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
    ```
    
2.  **å»¶è¿ŸåŠ è½½**ï¼š
    
    ```
    classÂ LazyRAGSystem:Â  Â Â defÂ __init__(self):Â  Â  Â  Â  self._encoder =Â NoneÂ  Â  Â  Â  self._reranker =Â NoneÂ  Â  @propertyÂ  Â Â defÂ encoder(self):Â  Â  Â  Â Â ifÂ self._encoderÂ isÂ None:Â  Â  Â  Â  Â  Â  self._encoder = SentenceTransformer("...")Â  Â  Â  Â Â returnÂ self._encoder
    ```
    
3.  **ä½¿ç”¨ CPU æ¨¡å¼**ï¼ˆå¦‚æœ GPU å†…å­˜ä¸è¶³ï¼‰ï¼š
    
    ```
    encoder = SentenceTransformer("...", device="cpu")
    ```
    

### 8.4 æ£€ç´¢ç»“æœä¸å‡†ç¡®

**é—®é¢˜**ï¼šæ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸æŸ¥è¯¢ä¸ç›¸å…³

**è§£å†³æ–¹æ¡ˆ**ï¼š

1.  **ä½¿ç”¨æ›´å¥½çš„ Embedding æ¨¡å‹**ï¼š
    
    ```
    # ä»all-MiniLM-L6-v2å‡çº§åˆ°BGE-largeencoder = SentenceTransformer("BAAI/bge-large-en-v1.5")
    ```
    
2.  **æ·»åŠ é‡æ’**ï¼š
    
    ```
    # ä½¿ç”¨é‡æ’æ¨¡å‹æå‡å‡†ç¡®æ€§reranker = AutoModelForSequenceClassification.from_pretrained("BAAI/bge-reranker-base")
    ```
    
3.  **è°ƒæ•´æ£€ç´¢å‚æ•°**ï¼š
    
    ```
    # å¢åŠ æ£€ç´¢æ•°é‡ï¼Œç„¶åé‡æ’retrieved_docs = self.retrieve(query, top_k=200) Â # å¢åŠ æ£€ç´¢æ•°é‡reranked_docs = self.rerank(query, retrieved_docs, top_k=10) Â # é‡æ’åå–Top-10
    ```
    

### 8.5 æ€§èƒ½ä¼˜åŒ–

**é—®é¢˜**ï¼šæŸ¥è¯¢é€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š

1.  **ä½¿ç”¨åˆé€‚çš„ç´¢å¼•**ï¼š
    
    ```
    # HNSWç´¢å¼•é€‚åˆä½å»¶è¿Ÿåœºæ™¯index_params = {Â  Â Â "index_type":Â "HNSW",Â  Â Â "params": {"M":Â 16,Â "efConstruction":Â 200}}
    ```
    
2.  **æ‰¹é‡å¤„ç†**ï¼š
    
    ```
    # æ‰¹é‡æŸ¥è¯¢æ¯”å•ä¸ªæŸ¥è¯¢æ›´é«˜æ•ˆresults = batch_search(queries, batch_size=32)
    ```
    
3.  **ç¼“å­˜ç»“æœ**ï¼š
    
    ```
    # ç¼“å­˜å¸¸è§æŸ¥è¯¢çš„ç»“æœcached_results = cache.get(query)ifÂ cached_results:Â  Â Â returnÂ cached_results
    ```
    

* * *

9. æ€»ç»“
-----

æœ¬æ–‡ä»‹ç»äº†å¦‚ä½•ä»é›¶å¼€å§‹åŸºäº Milvus æ„å»ºé«˜æ€§èƒ½ RAG ç³»ç»Ÿï¼Œæ¶µç›–äº†æ•°æ®å‡†å¤‡ã€å‘é‡æ£€ç´¢ã€ç»“æœé‡æ’ã€ä½ç½®ä¼˜åŒ–ç­‰æ ¸å¿ƒç¯èŠ‚ã€‚

**å…³é”®è¦ç‚¹**ï¼š

*   âœ…Â **ä½ç½®ä¼˜åŒ–æ˜¯å…³é”®**ï¼šé€šè¿‡å°†æœ€ç›¸å…³æ–‡æ¡£æ”¾åœ¨å¼€å¤´ï¼Œå¯ä»¥çªç ´ U å‹é™·é˜±ï¼Œæå‡ 22% çš„å‡†ç¡®ç‡
    
*   âœ…Â **é‡æ’æå‡å‡†ç¡®æ€§**ï¼šä½¿ç”¨ BGE-Reranker ç­‰é‡æ’æ¨¡å‹å¯ä»¥æ˜¾è‘—æå‡æ£€ç´¢æ•ˆæœ
    
*   âœ…Â **ç´¢å¼•é€‰æ‹©å¾ˆé‡è¦**ï¼šæ ¹æ®æ•°æ®è§„æ¨¡å’Œæ€§èƒ½éœ€æ±‚é€‰æ‹©åˆé€‚çš„ç´¢å¼•ç±»å‹ï¼ˆHNSWã€IVF ç­‰ï¼‰
    
*   âœ…Â **ç”Ÿäº§ç¯å¢ƒéœ€å®Œå–„**ï¼šé”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•ã€æ€§èƒ½ç›‘æ§æ˜¯ç”Ÿäº§ç¯å¢ƒå¿…å¤‡åŠŸèƒ½
    

å¸Œæœ›æœ¬æ–‡èƒ½å¸®åŠ©ä½ æ„å»ºé«˜æ€§èƒ½çš„ RAG ç³»ç»Ÿã€‚æ›´å¤šæŠ€æœ¯ç»†èŠ‚å’Œä»£ç ç¤ºä¾‹è¯·å‚è€ƒæ–‡ä¸­å„ç« èŠ‚å†…å®¹ã€‚

* * *

é™„å½•ï¼šå®Œæ•´ä»£ç ç¤ºä¾‹
---------

### A. å®Œæ•´çš„æ•°æ®å‡†å¤‡è„šæœ¬

```
"""å®Œæ•´çš„æ•°æ®å‡†å¤‡è„šæœ¬"""fromÂ pymilvusÂ importÂ MilvusClientfromÂ sentence_transformersÂ importÂ SentenceTransformerdefÂ prepare_data():Â  Â Â # 1. è¿æ¥MilvusÂ  Â  client = MilvusClient(uri="./milvus_demo.db")Â  Â  collection_name =Â "documents"Â  Â Â # 2. å‡†å¤‡æ–‡æ¡£Â  Â  documents = [Â  Â  Â  Â  {Â  Â  Â  Â  Â  Â Â "text":Â "Milvus is an open-source vector database designed for AI applications...",Â  Â  Â  Â  Â  Â Â "doc_id":Â "doc_001",Â  Â  Â  Â  Â  Â Â "title":Â "Introduction to Milvus"Â  Â  Â  Â  },Â  Â  Â  Â Â # ... æ›´å¤šæ–‡æ¡£Â  Â  ]Â  Â Â # 3. åˆå§‹åŒ–Embeddingæ¨¡å‹Â  Â  encoder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")Â  Â  dimension =Â 384Â  Â Â # 4. åˆ›å»ºé›†åˆÂ  Â Â ifÂ client.has_collection(collection_name):Â  Â  Â  Â  client.drop_collection(collection_name)Â  Â  client.create_collection(Â  Â  Â  Â  collection_,Â  Â  Â  Â  auto_id=True,Â  Â  )Â  Â Â # 5. ç”Ÿæˆå‘é‡å¹¶æ’å…¥Â  Â  texts = [doc["text"]Â forÂ docÂ inÂ documents]Â  Â  embeddings = encoder.encode(texts, normalize_embeddings=True)Â  Â  data = [Â  Â  Â  Â  {Â  Â  Â  Â  Â  Â Â "vector": emb.tolist(),Â  Â  Â  Â  Â  Â Â "text": doc["text"],Â  Â  Â  Â  Â  Â Â "doc_id": doc["doc_id"],Â  Â  Â  Â  Â  Â Â "title": doc["title"],Â  Â  Â  Â  }Â  Â  Â  Â Â forÂ emb, docÂ inÂ zip(embeddings, documents)Â  Â  ]Â  Â  client.insert(collection_âœ“ æ•°æ®å‡†å¤‡å®Œæˆï¼Œå…±Â {len(data)}Â ä¸ªæ–‡æ¡£")ifÂ __name__ ==Â "__main__":Â  Â  prepare_data()
```

### B. å®Œæ•´çš„ RAG ç³»ç»Ÿå®ç°

```
"""å®Œæ•´çš„ä¼˜åŒ–RAGç³»ç»Ÿå®ç°"""fromÂ pymilvusÂ importÂ MilvusClientfromÂ sentence_transformersÂ importÂ SentenceTransformerfromÂ transformersÂ importÂ AutoModelForSequenceClassification, AutoTokenizerfromÂ typingÂ importÂ List, Dict, AnyimportÂ torchclassÂ OptimizedRAGSystem:Â  Â Â """ä¼˜åŒ–çš„RAGç³»ç»Ÿ"""Â  Â Â defÂ __init__(Â  Â  Â  Â  self,Â  Â  Â  Â  milvus_uri: str =Â "./milvus_demo.db",Â  Â  Â  Â  collection_name: str =Â "documents",Â  Â  Â  Â  embedding_model: str =Â "sentence-transformers/all-MiniLM-L6-v2",Â  Â  Â  Â  reranker_model: str = None,Â  Â  ):Â  Â  Â  Â Â # è¿æ¥MilvusÂ  Â  Â  Â  self.client = MilvusClient(uri=milvus_uri)Â  Â  Â  Â  self.collection_name = collection_nameÂ  Â  Â  Â Â # åˆå§‹åŒ–Embeddingæ¨¡å‹Â  Â  Â  Â  self.encoder = SentenceTransformer(embedding_model)Â  Â  Â  Â Â # åˆå§‹åŒ–é‡æ’æ¨¡å‹ï¼ˆå¯é€‰ï¼‰Â  Â  Â  Â  self.reranker =Â NoneÂ  Â  Â  Â  self.reranker_tokenizer =Â NoneÂ  Â  Â  Â Â ifÂ reranker_model:Â  Â  Â  Â  Â  Â  self.reranker = AutoModelForSequenceClassification.from_pretrained(reranker_model)Â  Â  Â  Â  Â  Â  self.reranker_tokenizer = AutoTokenizer.from_pretrained(reranker_model)Â  Â  Â  Â  Â  Â  self.reranker.eval()Â  Â Â defÂ retrieve(self, query: str, top_k: int =Â 100):Â  Â  Â  Â Â """å‘é‡æ£€ç´¢"""Â  Â  Â  Â  query_vector = self.encoder.encode(query, normalize_embeddings=True).tolist()Â  Â  Â  Â  results = self.client.search(Â  Â  Â  Â  Â  Â  collection_name=self.collection_name,Â  Â  Â  Â  Â  Â  data=[query_vector],Â  Â  Â  Â  Â  Â  limit=top_k,Â  Â  Â  Â  Â  Â  search_params={"metric_type":Â "L2",Â "params": {}},Â  Â  Â  Â  Â  Â  output_fields=["text",Â "doc_id",Â "title"]Â  Â  Â  Â  )Â  Â  Â  Â  retrieved_docs = []Â  Â  Â  Â Â forÂ hitÂ inÂ results[0]:Â  Â  Â  Â  Â  Â  retrieved_docs.append({Â  Â  Â  Â  Â  Â  Â  Â Â "id": hit.get("id",Â ""),Â  Â  Â  Â  Â  Â  Â  Â Â "text": hit.get("entity", {}).get("text",Â ""),Â  Â  Â  Â  Â  Â  Â  Â Â "score": hit.get("distance",Â 0.0),Â  Â  Â  Â  Â  Â  Â  Â Â "doc_id": hit.get("entity", {}).get("doc_id",Â ""),Â  Â  Â  Â  Â  Â  Â  Â Â "title": hit.get("entity", {}).get("title",Â ""),Â  Â  Â  Â  Â  Â  })Â  Â  Â  Â Â returnÂ retrieved_docsÂ  Â Â defÂ rerank(self, query: str, documents: List[str], top_k: int =Â 10):Â  Â  Â  Â Â """é‡æ’"""Â  Â  Â  Â Â ifÂ self.rerankerÂ isNoneorÂ len(documents) ==Â 0:Â  Â  Â  Â  Â  Â Â returnÂ documents[:top_k]Â  Â  Â  Â  pairs = [[query, doc]Â forÂ docÂ inÂ documents]Â  Â  Â  Â Â withÂ torch.no_grad():Â  Â  Â  Â  Â  Â  inputs = self.reranker_tokenizer(Â  Â  Â  Â  Â  Â  Â  Â  pairs, padding=True, truncation=True, return_tensors="pt", max_length=512Â  Â  Â  Â  Â  Â  )Â  Â  Â  Â  Â  Â  scores = self.reranker(**inputs).logits.squeeze(-1)Â  Â  Â  Â  Â  Â  ranked_indices = scores.argsort(descending=True)Â  Â  Â  Â  Â  Â Â returnÂ [documents[idx]Â forÂ idxÂ inÂ ranked_indices[:top_k]]Â  Â Â defÂ build_context(self, query: str, retrieved_docs: List[Dict[str, Any]])Â -> str:Â  Â  Â  Â Â """æ„å»ºä¸Šä¸‹æ–‡ï¼ˆä½ç½®ä¼˜åŒ–ï¼‰"""Â  Â  Â  Â  sorted_docs = sorted(Â  Â  Â  Â  Â  Â  retrieved_docs,Â  Â  Â  Â  Â  Â  key=lambdaÂ x: x.get("score",Â 0)Â ifÂ isinstance(x.get("score"), (int, float))Â else0,Â  Â  Â  Â  Â  Â  reverse=TrueÂ  Â  Â  Â  )Â  Â  Â  Â  context_parts = ["ç³»ç»Ÿæç¤ºï¼šè¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”é—®é¢˜ã€‚\n"]Â  Â  Â  Â Â # æœ€ç›¸å…³æ–‡æ¡£ï¼ˆå¼€å¤´ï¼‰Â  Â  Â  Â  context_parts.append("# æœ€ç›¸å…³æ–‡æ¡£ï¼ˆå¼€å¤´ä½ç½®ï¼‰\n")Â  Â  Â  Â Â forÂ i, docÂ inÂ enumerate(sorted_docs[:3],Â 1):Â  Â  Â  Â  Â  Â  context_parts.append(f"æ–‡æ¡£Â {i}ï¼š{doc.get('text',Â '')}\n")Â  Â  Â  Â Â # æ¬¡ç›¸å…³æ–‡æ¡£ï¼ˆä¸­é—´ï¼‰Â  Â  Â  Â Â ifÂ len(sorted_docs) >Â 3:Â  Â  Â  Â  Â  Â  context_parts.append("\n# æ¬¡ç›¸å…³æ–‡æ¡£ï¼ˆä¸­é—´ä½ç½®ï¼‰\n")Â  Â  Â  Â  Â  Â Â forÂ i, docÂ inÂ enumerate(sorted_docs[3:7],Â 4):Â  Â  Â  Â  Â  Â  Â  Â  context_parts.append(f"æ–‡æ¡£Â {i}ï¼š{doc.get('text',Â '')}\n")Â  Â  Â  Â Â # ç”¨æˆ·é—®é¢˜ï¼ˆç»“å°¾ï¼‰Â  Â  Â  Â  context_parts.append("\n# ç”¨æˆ·é—®é¢˜ï¼ˆç»“å°¾ä½ç½®ï¼‰\n")Â  Â  Â  Â  context_parts.append(f"ç”¨æˆ·é—®é¢˜ï¼š{query}")Â  Â  Â  Â Â return"\n".join(context_parts)Â  Â Â defÂ query(self, user_query: str, retrieve_top_k: int =Â 100, rerank_top_k: int =Â 10):Â  Â  Â  Â Â """å®Œæ•´æŸ¥è¯¢æµç¨‹"""Â  Â  Â  Â Â # 1. æ£€ç´¢Â  Â  Â  Â  retrieved_docs = self.retrieve(user_query, top_k=retrieve_top_k)Â  Â  Â  Â Â # 2. é‡æ’Â  Â  Â  Â Â ifÂ self.reranker:Â  Â  Â  Â  Â  Â  doc_texts = [doc["text"]Â forÂ docÂ inÂ retrieved_docs]Â  Â  Â  Â  Â  Â  reranked_texts = self.rerank(user_query, doc_texts, top_k=rerank_top_k)Â  Â  Â  Â  Â  Â  text_to_doc = {doc["text"]: docÂ forÂ docÂ inÂ retrieved_docs}Â  Â  Â  Â  Â  Â  reranked_docs = [text_to_doc[text]Â forÂ textÂ inÂ reranked_texts]Â  Â  Â  Â Â else:Â  Â  Â  Â  Â  Â  reranked_docs = retrieved_docs[:rerank_top_k]Â  Â  Â  Â Â # 3. æ„å»ºä¸Šä¸‹æ–‡Â  Â  Â  Â  context = self.build_context(user_query, reranked_docs)Â  Â  Â  Â Â returnÂ {Â  Â  Â  Â  Â  Â Â "query": user_query,Â  Â  Â  Â  Â  Â Â "context": context,Â  Â  Â  Â  Â  Â Â "documents": reranked_docsÂ  Â  Â  Â  }# ä½¿ç”¨ç¤ºä¾‹ifÂ __name__ ==Â "__main__":Â  Â  rag = OptimizedRAGSystem()Â  Â  result = rag.query("What is Milvus?")Â  Â  print(result["context"])
```

* * *

**æ„Ÿè°¢é˜…è¯»ï¼å¸Œæœ›æœ¬æ–‡èƒ½å¸®åŠ©ä½ æ„å»ºé«˜æ€§èƒ½çš„ RAG ç³»ç»Ÿã€‚å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿äº¤æµè®¨è®ºã€‚**

-END -

**å¦‚æœæ‚¨å…³æ³¨å‰ç«¯ + AI ç›¸å…³é¢†åŸŸå¯ä»¥æ‰«ç è¿›ç¾¤äº¤æµ**

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/cAd6ObKOzEArGqlLlZmLVB61keywZ2APgWHNwTdK8OicE1utUcAJj1m5ZMFTL8iac51bGglnIeCR5KHicCBh5lh3A/640?wx_fmt=jpeg#imgIndex=0)

æ·»åŠ å°ç¼–å¾®ä¿¡è¿›ç¾¤ğŸ˜Š  

å…³äºå¥‡èˆå›¢
-----

å¥‡èˆå›¢æ˜¯ 360 é›†å›¢æœ€å¤§çš„å¤§å‰ç«¯å›¢é˜Ÿï¼Œéå¸¸é‡è§†äººæ‰åŸ¹å…»ï¼Œæœ‰å·¥ç¨‹å¸ˆã€è®²å¸ˆã€ç¿»è¯‘å®˜ã€ä¸šåŠ¡æ¥å£äººã€å›¢é˜Ÿ Leader ç­‰å¤šç§å‘å±•æ–¹å‘ä¾›å‘˜å·¥é€‰æ‹©ï¼Œå¹¶è¾…ä»¥æä¾›ç›¸åº”çš„æŠ€æœ¯åŠ›ã€ä¸“ä¸šåŠ›ã€é€šç”¨åŠ›ã€é¢†å¯¼åŠ›ç­‰åŸ¹è®­è¯¾ç¨‹ã€‚å¥‡èˆå›¢ä»¥å¼€æ”¾å’Œæ±‚è´¤çš„å¿ƒæ€æ¬¢è¿å„ç§ä¼˜ç§€äººæ‰å…³æ³¨å’ŒåŠ å…¥å¥‡èˆå›¢ã€‚  

![](https://mmbiz.qpic.cn/mmbiz_png/cAd6ObKOzEBLicibtcprJISN18FgTtg2N1ichPnMqRhicrP20VfwnC4vday7gtEoiaSynIH1bas4N5kgicliakrLdtT2Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1#imgIndex=1)